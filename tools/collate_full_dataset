#! /usr/bin/env python3

import logging
logging.basicConfig(level=logging.INFO)

import argparse
import sys
import os

import csv
import json
import yaml

from timeline import Timeline, TASKENGAGEMENT, SOCIALENGAGEMENT, SOCIALATTITUDE, MISSINGDATA

CHILDCHILD = "childchild"
CHILDROBOT = "childrobot"

# separator used to concatenate annotations when the do not match
SEPARATOR= "+"

FPS=30.

PURPLE_TOPIC="camera_purple/rgb/image_raw/compressed"
YELLOW_TOPIC="camera_yellow/rgb/image_raw/compressed"

MIN_CONFIDENCE_FACE=0.2
MIN_CONFIDENCE_SKEL=0.05

NOSE_FACE=30 # idx of nose in the facial landmarks
NOSE_SKEL=0 # idx of nose in the skeleton joints

# face and skeleton indices are described here:
# https://github.com/freeplay-sandbox/analysis#format-of-poses-files
PURPLE_FACE_KEYS=["purple_child_face%02d_%s" % (i, s) for i in range(70) for s in 'xy']
YELLOW_FACE_KEYS=["yellow_child_face%02d_%s" % (i, s) for i in range(70) for s in 'xy']

PURPLE_SKEL_KEYS=["purple_child_skel%02d_%s" % (i, s) for i in range(18) for s in 'xy']
YELLOW_SKEL_KEYS=["yellow_child_skel%02d_%s" % (i, s) for i in range(18) for s in 'xy']

FIELDNAMES = ['timestamp',
              'id', 
              'condition', 
              'annotators', 
              "purple_child_age", "yellow_child_age", 
              "purple_child_gender", "yellow_child_gender"] + \
              ["purple_frame_idx", "yellow_frame_idx"] + \
              PURPLE_FACE_KEYS + YELLOW_FACE_KEYS +\
              PURPLE_SKEL_KEYS + YELLOW_SKEL_KEYS +\
              ["purple_child_head_x", "purple_child_head_y", "purple_child_head_z",
               "purple_child_head_yaw", "purple_child_head_pitch", "purple_child_head_roll",  # head pose estimation, relative to centre of interactive table
               "yellow_child_head_x", "yellow_child_head_y", "yellow_child_head_z",
               "yellow_child_head_yaw", "yellow_child_head_pitch", "yellow_child_head_roll",  # head pose estimation, relative to centre of interactive table
               "purple_child_gaze_x", "purple_child_gaze_y", "purple_child_gaze_z", # gaze vector, origin at the 0,0,0 of the face (sellion)
               "yellow_child_gaze_x", "yellow_child_gaze_y", "yellow_child_gaze_z",
               "purple_child_au01",
               "purple_child_au02",
               "purple_child_au04",
               "purple_child_au05",
               "purple_child_au06",
               "purple_child_au07",
               "purple_child_au09",
               "purple_child_au10",
               "purple_child_au12",
               "purple_child_au14",
               "purple_child_au15",
               "purple_child_au17",
               "purple_child_au20",
               "purple_child_au23",
               "purple_child_au25",
               "purple_child_au26",
               "purple_child_au28",
               "purple_child_au45",
               "yellow_child_au01",
               "yellow_child_au02",
               "yellow_child_au04",
               "yellow_child_au05",
               "yellow_child_au06",
               "yellow_child_au07",
               "yellow_child_au09",
               "yellow_child_au10",
               "yellow_child_au12",
               "yellow_child_au14",
               "yellow_child_au15",
               "yellow_child_au17",
               "yellow_child_au20",
               "yellow_child_au23",
               "yellow_child_au25",
               "yellow_child_au26",
               "yellow_child_au28",
               "yellow_child_au45"] +\
               ["purple_child_motion_intensity_avg",
                "purple_child_motion_intensity_stdev",
                "purple_child_motion_intensity_max",
                "purple_child_motion_direction_avg",
                "purple_child_motion_direction_stdev",
                "yellow_child_motion_intensity_avg",
                "yellow_child_motion_intensity_stdev",
                "yellow_child_motion_intensity_max",
                "yellow_child_motion_direction_avg",
                "yellow_child_motion_direction_stdev"] +\
              ["audio%02d" % i for i in range(16)] +\
              ["purple_child_task_engagement", "purple_child_social_engagement", "purple_child_social_attitude",
              "yellow_child_task_engagement", "yellow_child_social_engagement", "yellow_child_social_attitude"]

CHECKS_FIELDNAMES = ['id', 
                     'annotators',
                     'timestamp_bagfile_start', 
                     'timestamp_bagfile_end', 
                     'timestamp_first_purple_image', 
                     'timestamp_last_purple_image', 
                     'timestamp_first_yellow_image', 
                     'timestamp_last_yellow_image', 
                     'nb_purple_images_bag', 'nb_purple_poses', 
                     'nb_yellow_images_bag', 'nb_yellow_poses', 
                     'timestamp_first_annotation', 
                     'timestamp_last_annotation']

class Dataset:

    def __init__(self, root):

        self.dataset = []

        self.total_nb_recordings = 0
        self.paths = []

        logging.info("Looking for recordings...")

        for dirpath, dirs, files in os.walk(root, topdown=False):
            for name in files:
                fullpath = os.path.join(dirpath, name)
                if name == "experiment.yaml":
                    if dirpath.split(os.sep)[-1].startswith("exclude_"):
                        logging.debug("%s has been excluded" % fullpath)
                        continue
                    self.total_nb_recordings += 1
                    self.paths.append(dirpath)

        logging.info("Found %d valid recordings" % self.total_nb_recordings)
        logging.info("%d fields to store per recorded frame" % len(FIELDNAMES))

        self.last_timestamp = 0
        self.last_purple_timestamp = 0
        self.last_yellow_timestamp = 0

    def ischildchild(self, path):
        with open(os.path.join(path, "experiment.yaml"), 'r') as yml:
            expe = yaml.load(yml)
            return expe["condition"] == CHILDCHILD

    def frame_at(self, timestamp, frames, start_at=0):
        
        startidx=max(0, start_at-5)

        for idx, frame in enumerate(frames[startidx:]):
            if abs(frame["ts"] - timestamp) < 0.5 * 1/FPS:
                return startidx+idx, frame
            if frame["ts"] > timestamp + 1:
                #logging.error("Frame for timestamp %s not found!" % timestamp)
                return -1, None

        #logging.error("Frame for timestamp %s not found!" % timestamp)
        return -1, None

    def get_annotations(self, annotators_list, timestamp, only_complete):

        annotators = annotators_list.split(SEPARATOR)

        result = {}

        constructs = ["purple_child_task_engagement",
                      "purple_child_social_engagement",
                      "purple_child_social_attitude",
                      "yellow_child_task_engagement",
                      "yellow_child_social_engagement",
                      "yellow_child_social_attitude"]

        for c in constructs:

            annotations = set()
            for annotator in annotators:
                ann = self.annotations[annotator][c].attime(timestamp)
                if ann != MISSINGDATA:
                    annotations.add(ann)

            if annotations:
                result[c] = SEPARATOR.join(annotations)
            elif only_complete:
                return None

        return result

    def processpath(self, path, writer, checks_writer, only_complete, duplicate_records):

        #################################################################
        #################################################################
        with open(os.path.join(path, "experiment.yaml"), 'r') as yml:
            expe = yaml.load(yml)

        #################################################################
        #################################################################
        with open(os.path.join(path, "freeplay.bag.yaml"), 'r') as yml:
            bagfile = yaml.load(yml)

        #################################################################
        #################################################################
        logging.info("Opening annotations...")

        self.annotations = {}
        annotator = None

        for file in os.listdir(path):
            if file.startswith("freeplay.annotations.") and file.endswith(".yaml"):
                annotationfile = os.path.join(path, file)
                annotator = file.split("freeplay.annotations.")[1].split(".yaml")[0]

                with open(annotationfile, 'r') as yml:
                    raw = yaml.load(yml)
                    annotation_timelines = {
                            "purple_child_task_engagement": Timeline(TASKENGAGEMENT, raw["purple"]),
                            "purple_child_social_engagement": Timeline(SOCIALENGAGEMENT, raw["purple"]),
                            "purple_child_social_attitude": Timeline(SOCIALATTITUDE, raw["purple"]),
                            "yellow_child_task_engagement": Timeline(TASKENGAGEMENT, raw["yellow"]),
                            "yellow_child_social_engagement": Timeline(SOCIALENGAGEMENT, raw["yellow"]),
                            "yellow_child_social_attitude": Timeline(SOCIALATTITUDE, raw["yellow"])
                            }
                    self.annotations[annotator] = annotation_timelines

        if len(self.annotations) == 0 and only_complete:
            logging.info("Skipping %s as no annotations and 'only complete' requested" % path)
            return
        if len(self.annotations) > 1:
            logging.info("%s: coded by %d annotators." % (path, len(self.annotations)))
            if duplicate_records:
                logging.info("--duplicate-records passed: I will accordingly duplicate this recording %d times." % len(self.annotations))
            else:
                logging.info("Divergent annotations will be concatenated.")

        #################################################################
        #################################################################
        logging.info("Opening freeplay.poses.json...")
        poses_json_file = os.path.join(path, "freeplay.poses.json")
        if not os.path.isfile(poses_json_file):
            logging.warning("%s has no freeplay.poses.json" % path)
            return

        with open(poses_json_file, 'r') as poses_json:
            poses = json.load(poses_json)


        #################################################################
        #################################################################
        #### COLLATE

        if duplicate_records:
            if len(self.annotations) == 0:
                localwriter = writer
                if localwriter is None:
                    logging.info("Writing to %s" % os.path.join(path,"pinsoro-complete-no-annotations.csv"))
                    f = open(os.path.join(path,"pinsoro-complete-no-annotations.csv"), 'w')
                    localwriter = csv.DictWriter(f, fieldnames=FIELDNAMES)
                    localwriter.writeheader()

                self.collate(path, localwriter, checks_writer, only_complete, None, expe, bagfile, poses)
            else:
                    for annotator in self.annotations.keys():
                        localwriter = writer
                        if localwriter is None:
                            logging.info("Writing to %s" % os.path.join(path,"pinsoro-complete-%s.csv" % annotator))
                            f = open(os.path.join(path,"pinsoro-complete-%s.csv" % annotator), 'w')
                            localwriter = csv.DictWriter(f, fieldnames=FIELDNAMES)
                            localwriter.writeheader()


                        self.collate(path, localwriter, checks_writer, only_complete, annotator, expe, bagfile, poses)

        else: # concatenate divergent annotations

            localwriter = writer
            if localwriter is None:

                id=path.split("/")[-1],
                logging.info("Writing to %s" % os.path.join(path,"pinsoro-%s.csv" % id))
                f = open(os.path.join(path,"pinsoro-%s.csv" % id), 'w')
                localwriter = csv.DictWriter(f, fieldnames=FIELDNAMES)
                localwriter.writeheader()

            annotators = SEPARATOR.join(self.annotations.keys())
            self.collate(path, localwriter, checks_writer, only_complete, annotators, expe, bagfile, poses)



    def collate(self, path, writer, checks_writer, only_complete, annotators, expe, bagfile, poses):
        #################################################################
        #################################################################
        #################################################################
        rows = []
        checks_row = {}

        ts_first_purple = poses[PURPLE_TOPIC]["frames"][0]["ts"]
        ts_first_yellow = poses[YELLOW_TOPIC]["frames"][0]["ts"]
        ts_last_purple = poses[PURPLE_TOPIC]["frames"][-1]["ts"]
        ts_last_yellow = poses[YELLOW_TOPIC]["frames"][-1]["ts"]

        ##############################################################
        ##############################################################
        #### Save dataset metadata for later sanity checks
        ##############################################################


        checks_row["id"] = path.split("/")[-1]
        if annotators:
            checks_row["annotators"] = annotators
        checks_row["timestamp_first_purple_image"] = ts_first_purple
        checks_row["timestamp_first_yellow_image"] = ts_first_yellow
        checks_row["timestamp_last_purple_image"] = ts_last_purple
        checks_row["timestamp_last_yellow_image"] = ts_last_yellow

        checks_row["timestamp_bagfile_start"] = bagfile["start"]
        checks_row["timestamp_bagfile_end"] = bagfile["end"]

        checks_row["nb_purple_images_bag"] = [t["messages"] for t in bagfile["topics"] if t["topic"] == PURPLE_TOPIC][0]
        checks_row["nb_purple_poses"] = len(poses[PURPLE_TOPIC]["frames"])
        checks_row["nb_yellow_images_bag"] = [t["messages"] for t in bagfile["topics"] if t["topic"] == YELLOW_TOPIC][0]
        checks_row["nb_yellow_poses"] = len(poses[YELLOW_TOPIC]["frames"])

        if annotators:
            checks_row["timestamp_first_annotation"] = "/".join(["%s: %s" % (a, min([t.start for t in self.annotations[a].values()])) for a in annotators.split(SEPARATOR)])
            checks_row["timestamp_last_annotation"] = "/".join(["%s: %s" % (a,max([t.end for t in self.annotations[a].values()])) for a in annotators.split(SEPARATOR)])

        checks_writer.writerow(checks_row)

        ##############################################################
        ##############################################################
        ##############################################################


        # the starting timestamp is *not* bagfile["start"], but instead the timestamp contained in the header of the first published frame (which is *before* is was recorded in the bagfile.
        ts = min(ts_first_purple, ts_first_yellow)

        # we need to store the bagfile delta as annotations are timestamped relative to the bagfile start time, *not* the frames timestamps
        bagfile_delta = bagfile["start"] - ts

        last_ts = max(ts_last_purple, ts_last_yellow)

        duration = last_ts - ts
        logging.info("Collating features (%0.2f sec of data)..." % duration)

        last_percent = 0
        purple_idx = 0
        yellow_idx = 0
        while ts < last_ts:

            skip_row = False

            row = {"timestamp": ts,
                    "condition": "childchild" if self.ischildchild(path) else "childrobot",
                    "id": path.split("/")[-1],
                    "purple_child_age": expe["purple-participant"]["age"],
                    "purple_child_gender": expe["purple-participant"]["gender"],
                    "yellow_child_age": expe["yellow-participant"]["age"],
                    "yellow_child_gender": expe["yellow-participant"]["gender"]}

            if annotators:
                row["annotators"] = annotators

            purple_idx, purple_frame = self.frame_at(ts, poses[PURPLE_TOPIC]["frames"], start_at=purple_idx)

            row["purple_frame_idx"] = purple_idx + 1
            if purple_frame:
                row.update(
                    self.formatpose("faces", 
                                    purple_frame, 
                                    PURPLE_FACE_KEYS, 
                                    NOSE_FACE,
                                    MIN_CONFIDENCE_FACE))

                row.update(
                    self.formatpose("poses", 
                                    purple_frame, 
                                    PURPLE_SKEL_KEYS, 
                                    NOSE_SKEL,
                                    MIN_CONFIDENCE_SKEL))


            yellow_idx, yellow_frame = self.frame_at(ts, poses[YELLOW_TOPIC]["frames"], start_at=yellow_idx)
            row["yellow_frame_idx"] = yellow_idx + 1
            if yellow_frame:
                row.update(
                    self.formatpose("faces", 
                                    yellow_frame, 
                                    YELLOW_FACE_KEYS, 
                                    NOSE_FACE,
                                    MIN_CONFIDENCE_FACE))

                row.update(
                    self.formatpose("poses", 
                                    yellow_frame, 
                                    YELLOW_SKEL_KEYS, 
                                    NOSE_SKEL,
                                    MIN_CONFIDENCE_SKEL))


            if annotators:
                anns = self.get_annotations(annotators, ts + bagfile_delta, only_complete)

                if anns is None: # this means 'only complete' was requested, but some annotations were missing
                    skip_row = True
                else:
                    row.update(anns)

            if not skip_row:
                rows.append(row)

            ts += 1/FPS

            percent = int((ts - (last_ts-duration)) / duration * 100)
            if percent != last_percent:
                logging.info("%d%% done" % percent)
                last_percent = percent
        
        writer.writerows(rows)


    def formatpose(self,
                    partname, 
                    frame, 
                    keys, 
                    idx_central_landmark, 
                    min_confidence_level):
        """
        :param idx_central_landmark: the index of one feature (for instance, the nose) that is expected to be close to the image centre. Used to select the right part when more than one face/skeleton has been detected.
        """

        ### First, select the face the closest to the center of the image

        if partname in frame and len(frame[partname]) > 0: # one face or more detected. Assume the correct one is the one closest to the image centre
            part = frame[partname]["1"]
            min_dist = pow(part[idx_central_landmark][0] - 0.5, 2) +\
                       pow(part[idx_central_landmark][1] - 0.5, 2)

            for p in frame[partname].values():
                dist = pow(p[idx_central_landmark][0] - 0.5, 2) +\
                       pow(p[idx_central_landmark][1] - 0.5, 2)

                if dist < min_dist:
                    part = p
                    min_dist = dist
        else:
            return {}

        results = {}
        for i in range(int(len(keys)/2)):
            x,y,c = part[i]
            if c > min_confidence_level:
                results[keys[i*2]] = x
                results[keys[i*2 + 1]] = y


        return results

    def write(self, writer, checks_writer, only_complete, duplicate_records):
        
        idx = 0
        for path in self.paths:
            idx += 1
            logging.info("[%02d/%02d] Processing %s" % (idx, len(self.paths), path))
            self.processpath(path, writer, checks_writer, only_complete, duplicate_records)


if __name__ == "__main__":

    parser = argparse.ArgumentParser(description='PInSoRo Dataset -- Full post-processed dataset collator')
    parser.add_argument("--data-check", nargs='?', type=argparse.FileType('w'), default=False, const=sys.stdout, help="run some consistency checks on the dataset while collating it. You can specify a filename to save as CSV (default to stdout)")
    parser.add_argument("--only-complete", action="store_true", help="Only complete datapoints (all features and annotations present) are recorded")
    parser.add_argument("--single-csv", help="name of the CSV file where the whole dataset should be recorded. By default, create one file per recording.")
    parser.add_argument("--duplicate-records", help="some recordings have multiple annotators. By default, when annotations diverge, they are concatenated with '%s' as separator. If this option is passed, the whole recording is instead duplicated, one per annotator. This is especially useful when the data is used as training dataset." % SEPARATOR)
    parser.add_argument("path", help="root path of the dataset -- recordings are recursively looked for from this path")

    args = parser.parse_args()

    dataset = Dataset(args.path)

    writer=None
    if args.single_csv:
        f = open(args.file, 'w')
        writer = csv.DictWriter(f, fieldnames=FIELDNAMES)
        writer.writeheader()

    dataset_checks_writer = csv.DictWriter(args.data_check, fieldnames=CHECKS_FIELDNAMES)
    dataset_checks_writer.writeheader()

    dataset.write(writer, dataset_checks_writer, args.only_complete, args.duplicate_records)



